{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2d52bddd",
   "metadata": {},
   "source": [
    "### Installing the Necessary Package"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f6b7953c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install huggingface_hub\n",
    "#!pip install langchain\n",
    "#!pip install python-dotenv\n",
    "#! pip install sentencepiece\n",
    "#! pip install transformers torch\n",
    "#! pip install accelerate -U"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "205bea90",
   "metadata": {},
   "source": [
    "| Package           | License         | Purpose                                                                                          |\n",
    "|-------------------|-----------------|--------------------------------------------------------------------------------------------------|\n",
    "| huggingface_hub   | Apache License 2.0 | A client library to download and publish models on the Hugging Face Hub.                           |\n",
    "| langchain         | MIT License     | A framework for chaining language models together to build applications.                          |\n",
    "| python-dotenv     | BSD 2-Clause \"Simplified\" License | Reads key-value pairs from a `.env` file and can set them as environment variables.               |\n",
    "| sentencepiece     | Apache License 2.0 | A library for unsupervised text tokenization, primarily used for neural network-based text processing. |\n",
    "| transformers      | Apache License 2.0 | A state-of-the-art natural language processing library for training, converting, and using models from Hugging Face. |\n",
    "| torch             | BSD License     | An open-source machine learning library developed by the Facebook AI Research lab.                 |\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95c92219",
   "metadata": {},
   "source": [
    "### API Key For  Hugging Face"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4cd829d2",
   "metadata": {},
   "source": [
    "To access the model from Hugging Face, an API key is required"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "390ae122",
   "metadata": {},
   "source": [
    "### Importing the Necessary Package"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "20e1c22e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "import pandas as pd\n",
    "import numpy as np \n",
    "import torch\n",
    "import logging\n",
    "from dotenv import load_dotenv ,find_dotenv"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f2b723a",
   "metadata": {},
   "source": [
    "### Loading API Token from .env File "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9e5a216c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up logging\n",
    "logging.basicConfig(level=logging.INFO)\n",
    "\n",
    "def load_api_token():\n",
    "    try:\n",
    "        # Load the .env file\n",
    "        load_dotenv()\n",
    "        # Retrieve the API token\n",
    "        api_token = os.getenv('HUGGINGFACEHUB_API_TOKEN')\n",
    "        if api_token is None:\n",
    "            raise ValueError(\"API key not found in .env file\")\n",
    "        return api_token\n",
    "    except Exception as e:\n",
    "        logging.error(f\"Error loading API token: {e}\")\n",
    "        return None\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "97069d42",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:API token loaded successfully\n"
     ]
    }
   ],
   "source": [
    "api_token = load_api_token()\n",
    "if api_token:\n",
    "    logging.info(\"API token loaded successfully\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b31d3526",
   "metadata": {},
   "source": [
    "For the sake of testing, I am including an API key in the code, but it is generally advised against embedding API keys directly in the codebase."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "97e7e574",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ[\"HUGGINGFACEHUB_API_TOKEN\"] = \"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\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47e00878",
   "metadata": {},
   "source": [
    "### Solution Part-1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e1d9ef2",
   "metadata": {},
   "source": [
    "###### 1: Use a pre-trained google/flan-t5-small as the model\n",
    "##### 2. Verify if the summariza'on task works.\n",
    "##### 3. Verify if the Q&A task works.\n",
    "##### 4. Verify if English to French transla'on task works"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67b2e79a",
   "metadata": {},
   "source": [
    "Google/FLAN-T5-small is a model developed by Google, combining two significant concepts in AI and machine learning: FLAN and T5.\n",
    "T5:Text-to-Text Transfer Transformer\n",
    "FLAN :Fine-tuned Language Net"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ee85e88",
   "metadata": {},
   "source": [
    "### Multiple methods to load the Flan-T5 Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "003e7af6",
   "metadata": {},
   "source": [
    "Although there are multiple methods to load the Flan-T5 Model, for demonstration purposes, I am opting to use Hugging Face hub using langchain and transformers."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d73689ce",
   "metadata": {},
   "source": [
    "### Approch 1: Using Transformers package"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5019edee",
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "from transformers import AutoTokenizer, AutoModelForSeq2SeqLM, pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c5eb168f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup logging\n",
    "logging.basicConfig(level=logging.INFO)\n",
    "logger = logging.getLogger(__name__)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c22ed8d3",
   "metadata": {},
   "source": [
    "### 1: Use a pre-trained google/flan-t5-small as the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "41281f16",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:__main__:Loading model: google/flan-t5-small\n",
      "INFO:__main__:Model loaded successfully\n"
     ]
    }
   ],
   "source": [
    "def load_model(model_name=\"google/flan-t5-small\"):\n",
    "    try:\n",
    "        logger.info(f\"Loading model: {model_name}\")\n",
    "        tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "        model = AutoModelForSeq2SeqLM.from_pretrained(model_name)\n",
    "        logger.info(\"Model loaded successfully\")\n",
    "        return tokenizer, model\n",
    "    except Exception as e:\n",
    "        logger.error(f\"An error occurred while loading the model: {e}\")\n",
    "        return None, None\n",
    "\n",
    "tokenizer, model = load_model()\n",
    "if tokenizer is not None and model is not None:\n",
    "    # Model usage here\n",
    "    pass\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea6b9d63",
   "metadata": {},
   "source": [
    "### 2. Verify if the summariza'on task works.\n",
    "### 3. Verify if the Q&A task works.\n",
    "### 4. Verify if English to French transla'on task works"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "67f4f61b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "719ee48c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Verify_flan_model:\n",
    "    def __init__(self, model_name=\"google/flan-t5-small\"):\n",
    "        self.logger = logger\n",
    "        try:\n",
    "            logger.info(f\"Loading model: {model_name}\")\n",
    "            self.tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "            self.model = AutoModelForSeq2SeqLM.from_pretrained(model_name)\n",
    "            self.logger.info(\"Model and tokenizer loaded successfully.\")\n",
    "        except Exception as e:\n",
    "            self.logger.error(f\"An error occurred while loading the model and tokenizer: {e}\")\n",
    "\n",
    "    def summarize(self, text_to_summarize):\n",
    "        try:\n",
    "            summarizer = pipeline(\"summarization\", model=self.model, tokenizer=self.tokenizer)\n",
    "            summary = summarizer(text_to_summarize)\n",
    "            self.logger.info(f\"Summarization: {summary}\")\n",
    "            return summary\n",
    "        except Exception as e:\n",
    "            self.logger.error(f\"An error occurred in summarization: {e}\")\n",
    "            return None\n",
    "\n",
    "    def answer_question(self, question, context):\n",
    "        try:\n",
    "            qa_input = f\"question: {question} context: {context}\"\n",
    "            answer = self.model.generate(**self.tokenizer(qa_input, return_tensors=\"pt\"))\n",
    "            decoded_answer = self.tokenizer.decode(answer[0])\n",
    "            self.logger.info(f\"Q&A: {decoded_answer}\")\n",
    "            return decoded_answer\n",
    "        except Exception as e:\n",
    "            self.logger.error(f\"An error occurred in Q&A: {e}\")\n",
    "            return None\n",
    "\n",
    "    def translate_to_french(self, text_to_translate):\n",
    "        try:\n",
    "            translator = pipeline(\"translation_en_to_fr\", model=self.model, tokenizer=self.tokenizer)\n",
    "            translation = translator(text_to_translate)\n",
    "            self.logger.info(f\"Translation: {translation}\")\n",
    "            return translation\n",
    "        except Exception as e:\n",
    "            self.logger.error(f\"An error occurred in translation: {e}\")\n",
    "            return None\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1628d1d0",
   "metadata": {},
   "source": [
    "### Verification : Executing the Function "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a9ae348d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:__main__:Loading model: google/flan-t5-small\n",
      "INFO:__main__:Model and tokenizer loaded successfully.\n",
      "Your max_length is set to 200, but your input_length is only 48. Since this is a summarization task, where outputs shorter than the input are typically wanted, you might consider decreasing max_length manually, e.g. summarizer('...', max_length=24)\n",
      "INFO:__main__:Summarization: [{'summary_text': \"India is one of the world's most diverse and diverse regions, and it is a country where ancient traditions blend seamlessly with modern advancements.\"}]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Summarization result: [{'summary_text': \"India is one of the world's most diverse and diverse regions, and it is a country where ancient traditions blend seamlessly with modern advancements.\"}]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:__main__:Q&A: <pad> Santa Clara, California, is the head office of ServiceNow, Inc., an American software company that develops a cloud computing platform to help companies manage digital workflows for enterprise operations.</s>\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Q&A result: <pad> Santa Clara, California, is the head office of ServiceNow, Inc., an American software company that develops a cloud computing platform to help companies manage digital workflows for enterprise operations.</s>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:__main__:Translation: [{'translation_text': \" c'est aujourd'hui d'aujourd'hui?  quoi est à l'heure actuelle? - et à la fois?\"}]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Translation result: [{'translation_text': \" c'est aujourd'hui d'aujourd'hui?  quoi est à l'heure actuelle? - et à la fois?\"}]\n"
     ]
    }
   ],
   "source": [
    "flan_model = Verify_flan_model()\n",
    "# Summarization example\n",
    "text_to_summarize = \"India, a country that conjures up a vivid kaleidoscope of images,is as diverse as it is vast. It is a land where ancient traditions blend seamlessly with modern advancements. \"\n",
    "print(\"Summarization result:\", flan_model.summarize(text_to_summarize))\n",
    "# Question Answering example\n",
    "question = \"where is head office of ServiceNow\"\n",
    "context = \"ServiceNow, Inc. is an American software company based in Santa Clara, California that develops a cloud computing platform to help companies manage digital workflows for enterprise operations\"\n",
    "print(\"Q&A result:\", flan_model.answer_question(question, context))\n",
    "# Translation example\n",
    "text_to_translate = \"How are you today?\"\n",
    "print(\"Translation result:\", flan_model.translate_to_french(text_to_translate))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9230c1cd",
   "metadata": {},
   "source": [
    "### Approch 2:Using  langchain and huggingface hub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c32357be",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.llms import HuggingFaceHub\n",
    "from langchain.prompts import PromptTemplate\n",
    "\n",
    "# Setup logging\n",
    "logging.basicConfig(level=logging.INFO)\n",
    "logger = logging.getLogger(__name__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c22257f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LanguageModelHandler:\n",
    "    def __init__(self, model_repo_id):\n",
    "        # Initialize HuggingFace Language Model\n",
    "        self.llm = HuggingFaceHub(repo_id=model_repo_id)\n",
    "    \n",
    "    def get_prompt(self, task, input_text, context=None):\n",
    "        if task == \"summarization\":\n",
    "            return f\"Summarize the following text: {input_text}\"\n",
    "        elif task == \"q&a\":\n",
    "            return f\"Question: {input_text}\\nContext: {context}\\nAnswer:\"\n",
    "        elif task == \"translation\":\n",
    "            return f\"Translate the following English text to French: {input_text}\"\n",
    "        else:\n",
    "            raise ValueError(\"Unsupported task\")\n",
    "    \n",
    "    def execute_task(self, task, input_text, context=None):\n",
    "        try:\n",
    "            prompt = self.get_prompt(task, input_text, context)\n",
    "            result = self.llm(prompt)\n",
    "            return result\n",
    "        except Exception as e:\n",
    "            logger.error(f\"An error occurred: {e}\")\n",
    "            return None\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98995c79",
   "metadata": {},
   "source": [
    "#### Verification : Executing the Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "9bfeb249",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Summarization: India is a country that has a thriving culture and culture, and is a\n",
      "Q&A: Santa Clara, California\n",
      "Translation: Comment est aujourd'hui?\n"
     ]
    }
   ],
   "source": [
    "# Create an instance of the class\n",
    "lm_handler = LanguageModelHandler(model_repo_id=\"google/flan-t5-small\")\n",
    "# Summarization Example\n",
    "summarization_input = \"India, a country that conjures up a vivid kaleidoscope of images,is as diverse as it is vast. It is a land where ancient traditions blend seamlessly with modern advancements. \"\n",
    "summary = lm_handler.execute_task(\"summarization\", summarization_input)\n",
    "print(f\"Summarization: {summary}\")\n",
    "# Q&A Example\n",
    "qa_question = \"where is head office of ServiceNow\"\n",
    "qa_context = \"ServiceNow, Inc. is an American software company based in Santa Clara, California that develops a cloud computing platform to help companies manage digital workflows for enterprise operations\"\n",
    "answer = lm_handler.execute_task(\"q&a\", qa_question, qa_context)\n",
    "print(f\"Q&A: {answer}\")\n",
    "\n",
    "# Translation Example\n",
    "translation_input = \"How are you today?\"\n",
    "translation = lm_handler.execute_task(\"translation\", translation_input)\n",
    "print(f\"Translation: {translation}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0e87450",
   "metadata": {},
   "source": [
    "## Solution  Part :2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58f65366",
   "metadata": {},
   "source": [
    "### 5.Print the names of all the model layers and their dimensions.\n",
    "### 6.Print the total number of parameters/weights in this model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "9bafdf58",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_model_hf_tf(model_name=\"transformers\"):\n",
    "    try:\n",
    "        if model_name == \"huggingface\":\n",
    "            # Assuming HuggingFaceHub is a custom function or class you have defined\n",
    "            # Replace 'HuggingFaceHub' with the actual function/class you're using to load the model\n",
    "            model = HuggingFaceHub(repo_id=\"google/flan-t5-large\")\n",
    "        elif model_name == \"transformers\":\n",
    "            tokenizer, model = load_model()\n",
    "        else:\n",
    "            raise ValueError(\"Unsupported model type specified\")\n",
    "        \n",
    "        logger.info(f\"Model loaded successfully: {model_name}\")\n",
    "        return model\n",
    "\n",
    "    except Exception as e:\n",
    "        logger.error(f\"An error occurred while loading the model: {e}\")\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "171e0d67",
   "metadata": {},
   "outputs": [],
   "source": [
    "#model = load_model_hf_tf(\"huggingface\")\n",
    "#model = load_model_hf_tf(\"transformers\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "60918424",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_model_details(model):\n",
    "    try:\n",
    "        # Initialize a list to store model details\n",
    "        model_details_list = []\n",
    "\n",
    "        # Iterate through model parameters and add to the list\n",
    "        for name, param in model.named_parameters():\n",
    "            model_details_list.append({'Layer Name': name, 'Dimension': str(param.size())})\n",
    "\n",
    "        # Convert list to DataFrame\n",
    "        model_details_df = pd.DataFrame(model_details_list)\n",
    "\n",
    "        # Calculate total parameters\n",
    "        total_params = sum(p.numel() for p in model.parameters())\n",
    "        logger.info(f\"Total number of parameters: {total_params}\")\n",
    "\n",
    "        return model_details_df, total_params\n",
    "\n",
    "    except Exception as e:\n",
    "        logger.error(f\"An error occurred: {e}\")\n",
    "        return pd.DataFrame(), 0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "4a7917ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:__main__:Loading model: google/flan-t5-small\n",
      "INFO:__main__:Model loaded successfully\n",
      "INFO:__main__:Model loaded successfully: transformers\n",
      "INFO:__main__:Total number of parameters: 76961152\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Layer Name</th>\n",
       "      <th>Dimension</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>shared.weight</td>\n",
       "      <td>torch.Size([32128, 512])</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>encoder.block.0.layer.0.SelfAttention.q.weight</td>\n",
       "      <td>torch.Size([384, 512])</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>encoder.block.0.layer.0.SelfAttention.k.weight</td>\n",
       "      <td>torch.Size([384, 512])</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>encoder.block.0.layer.0.SelfAttention.v.weight</td>\n",
       "      <td>torch.Size([384, 512])</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>encoder.block.0.layer.0.SelfAttention.o.weight</td>\n",
       "      <td>torch.Size([512, 384])</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>185</th>\n",
       "      <td>decoder.block.7.layer.2.DenseReluDense.wi_1.we...</td>\n",
       "      <td>torch.Size([1024, 512])</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>186</th>\n",
       "      <td>decoder.block.7.layer.2.DenseReluDense.wo.weight</td>\n",
       "      <td>torch.Size([512, 1024])</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>187</th>\n",
       "      <td>decoder.block.7.layer.2.layer_norm.weight</td>\n",
       "      <td>torch.Size([512])</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>188</th>\n",
       "      <td>decoder.final_layer_norm.weight</td>\n",
       "      <td>torch.Size([512])</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>189</th>\n",
       "      <td>lm_head.weight</td>\n",
       "      <td>torch.Size([32128, 512])</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>190 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            Layer Name  \\\n",
       "0                                        shared.weight   \n",
       "1       encoder.block.0.layer.0.SelfAttention.q.weight   \n",
       "2       encoder.block.0.layer.0.SelfAttention.k.weight   \n",
       "3       encoder.block.0.layer.0.SelfAttention.v.weight   \n",
       "4       encoder.block.0.layer.0.SelfAttention.o.weight   \n",
       "..                                                 ...   \n",
       "185  decoder.block.7.layer.2.DenseReluDense.wi_1.we...   \n",
       "186   decoder.block.7.layer.2.DenseReluDense.wo.weight   \n",
       "187          decoder.block.7.layer.2.layer_norm.weight   \n",
       "188                    decoder.final_layer_norm.weight   \n",
       "189                                     lm_head.weight   \n",
       "\n",
       "                    Dimension  \n",
       "0    torch.Size([32128, 512])  \n",
       "1      torch.Size([384, 512])  \n",
       "2      torch.Size([384, 512])  \n",
       "3      torch.Size([384, 512])  \n",
       "4      torch.Size([512, 384])  \n",
       "..                        ...  \n",
       "185   torch.Size([1024, 512])  \n",
       "186   torch.Size([512, 1024])  \n",
       "187         torch.Size([512])  \n",
       "188         torch.Size([512])  \n",
       "189  torch.Size([32128, 512])  \n",
       "\n",
       "[190 rows x 2 columns]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = load_model_hf_tf(\"transformers\")\n",
    "# Get model details\n",
    "model_info_df, total_parameters = get_model_details(model)\n",
    "\n",
    "# Display DataFrame\n",
    "model_info_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2bea6f6e",
   "metadata": {},
   "source": [
    "## Solution Part :3 "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "303fbc7e",
   "metadata": {},
   "source": [
    "### 7. Set the tensor in final layer (decoder.final_layer_norm.weight) to all zeros.\n",
    "### 8.Verify if the Q&A task works after resetting the weights of the above layer\n",
    "### 9.Replace the decoder.final_layer_norm.weight with a layer of smaller dimensions and adjust all the dependent layers to match the dimension"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "0d73e80d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:__main__:Loading model: google/flan-t5-small\n",
      "INFO:__main__:Model loaded successfully\n",
      "INFO:__main__:Model loaded successfully: transformers\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0.])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load the model\n",
    "model = load_model_hf_tf(\"transformers\")\n",
    "#Task 7: Set the tensor in the final layer to all zeros\n",
    "model.decoder.final_layer_norm.weight.data.zero_()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "fecdc1e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Task 8: Test the model's Q&A functionality"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "63ef0953",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_qa_functionality(model, question, context):\n",
    "    try:\n",
    "        qa_input = f\"question: {question} context: {context}\"\n",
    "        answer = model.generate(**tokenizer(qa_input, return_tensors=\"pt\"))\n",
    "        decoded_answer =tokenizer.decode(answer[0])\n",
    "        logger.info(f\"Q&A: {decoded_answer}\")\n",
    "        return decoded_answer\n",
    "    except Exception as e:\n",
    "        logger.error(f\"An error occurred in Q&A: {e}\")\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "f62fd54f",
   "metadata": {},
   "outputs": [],
   "source": [
    "qa_question = \"where is head office of ServiceNow\"\n",
    "qa_context = \"ServiceNow, Inc. is an American software company based in Santa Clara, California that develops a cloud computing platform to help companies manage digital workflows for enterprise operations\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "c1da63a5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:__main__:Q&A: <pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad>\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'<pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad>'"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_qa_functionality(model, qa_question, qa_context)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1fe9d7f1",
   "metadata": {},
   "source": [
    "#### Impact of Zeroing Weights"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a10733fb",
   "metadata": {},
   "source": [
    "By setting the weights of this normalization layer to zero, effectively nullify the normalization process. This drastic change disrupts the balance and scaling that the model relies on for generating coherent outputs.\n",
    "Without proper normalization, the subsequent layers (like the output linear layer) receive unnormalized or improperly scaled inputs, leading to unpredictable and likely meaningless outputs."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7e375de",
   "metadata": {},
   "source": [
    "### Pad "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf1852b0",
   "metadata": {},
   "source": [
    "The output  observing, a series of '<pad>' tokens, indicates that the model's ability to generate meaningful text is severely impaired. In T5 and similar models, the '<pad>' token is used to fill in sequences to a uniform length.\n",
    "When the model's internals are significantly disrupted (as is the case here), it might default to outputting '<pad>' tokens, essentially indicating that it cannot generate any meaningful text based on the given input."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75ddc6f6",
   "metadata": {},
   "source": [
    "### Summary :model.decoder.final_layer_norm.weight.data.zero_()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b160990c",
   "metadata": {},
   "source": [
    "In summary, setting the final layer normalization weights to zero disrupts the delicate balance and scaling within the model, leading to outputs that are essentially meaningless pad tokens. This demonstrates how critical each component of a transformer model is to its overall functionality and language generation capabilities."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a161ca8",
   "metadata": {},
   "source": [
    "Task 9:Replace the decoder.final_layer_norm.weight with a layer of smaller dimensions and \n",
    "adjust all the dependent layers to match the dimension"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "c80976a4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "layer: ModuleList(\n",
      "  (0): T5LayerSelfAttention(\n",
      "    (SelfAttention): T5Attention(\n",
      "      (q): Linear(in_features=512, out_features=384, bias=False)\n",
      "      (k): Linear(in_features=512, out_features=384, bias=False)\n",
      "      (v): Linear(in_features=512, out_features=384, bias=False)\n",
      "      (o): Linear(in_features=384, out_features=512, bias=False)\n",
      "    )\n",
      "    (layer_norm): T5LayerNorm()\n",
      "    (dropout): Dropout(p=0.1, inplace=False)\n",
      "  )\n",
      "  (1): T5LayerCrossAttention(\n",
      "    (EncDecAttention): T5Attention(\n",
      "      (q): Linear(in_features=512, out_features=384, bias=False)\n",
      "      (k): Linear(in_features=512, out_features=384, bias=False)\n",
      "      (v): Linear(in_features=512, out_features=384, bias=False)\n",
      "      (o): Linear(in_features=384, out_features=512, bias=False)\n",
      "    )\n",
      "    (layer_norm): T5LayerNorm()\n",
      "    (dropout): Dropout(p=0.1, inplace=False)\n",
      "  )\n",
      "  (2): T5LayerFF(\n",
      "    (DenseReluDense): T5DenseGatedActDense(\n",
      "      (wi_0): Linear(in_features=512, out_features=1024, bias=False)\n",
      "      (wi_1): Linear(in_features=512, out_features=1024, bias=False)\n",
      "      (wo): Linear(in_features=1024, out_features=512, bias=False)\n",
      "      (dropout): Dropout(p=0.1, inplace=False)\n",
      "      (act): NewGELUActivation()\n",
      "    )\n",
      "    (layer_norm): T5LayerNorm()\n",
      "    (dropout): Dropout(p=0.1, inplace=False)\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "# Inspect the last block of the decoder\n",
    "last_block = model.decoder.block[-1]\n",
    "\n",
    "# Print the components of the last block\n",
    "for name, module in last_block.named_children():\n",
    "    print(f\"{name}: {module}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "86ea9732",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "T5LayerNorm()"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "layer = last_block.layer[2].layer_norm\n",
    "layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "3a73f1db",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "\n",
    "def ModifyLayerDimensions(layer, new_size):\n",
    "    \"\"\"\n",
    "    Modify the dimensions of a given neural network layer.\n",
    "\n",
    "    Parameters:\n",
    "    layer (nn.Module): The layer to be modified.\n",
    "    new_size (int): The new dimension size.\n",
    "\n",
    "    Returns:\n",
    "    nn.Module: The modified layer.\n",
    "    \"\"\"\n",
    "\n",
    "    if isinstance(layer, nn.Linear):\n",
    "        # For a linear layer, change the number of output features\n",
    "        new_layer = nn.Linear(in_features=layer.in_features, out_features=new_size)\n",
    "        \n",
    "        # Optionally, copy the existing weights and biases, up to the new size\n",
    "        with torch.no_grad():\n",
    "            new_layer.weight[:layer.out_features, :new_size].copy_(layer.weight.data)\n",
    "            if layer.bias is not None:\n",
    "                new_layer.bias[:new_size].copy_(layer.bias.data)\n",
    "\n",
    "        return new_layer\n",
    "\n",
    "    else:\n",
    "        raise TypeError(\"Layer modification for this layer type is not implemented\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "9066fff2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a function to modify the model\n",
    "def modify_model(model, new_size):\n",
    "    try:\n",
    "        # Replace the final layer normalization in the decoder\n",
    "        model.decoder.final_layer_norm = torch.nn.LayerNorm(new_size)\n",
    "        # Adjust dependent layers\n",
    "        decoder_block = model.decoder.block[-1]\n",
    "        layer = decoder_block.layer[2].layer_norm\n",
    "        #model.decoder.some_layer = ModifyLayerDimensions(layer, new_size)\n",
    "        logger.info(\"Model modification successful.\")\n",
    "\n",
    "    except Exception as e:\n",
    "        logger.error(f\"An error occurred during model modification: {e}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "106cccb4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:__main__:Model modification successful.\n"
     ]
    }
   ],
   "source": [
    "# Define the new size\n",
    "new_size = 256 \n",
    "# Call the function to modify the model\n",
    "modify_model(model, new_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77d2959b",
   "metadata": {},
   "source": [
    "### Solution : Part 4"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70801146",
   "metadata": {},
   "source": [
    "### 10. Reload the original google/flan-t5-small model.\n",
    "#### 11. Train the model for a Q&A task that takes a context as addi'onal input along with the ques'on. You can use SQuAD dataset (h_ps://rajpurkar.github.io/SQuAD-explorer/ ) or the smaller Topioca dataset (h_ps://mcgill-nlp.github.io/topiocqa/) . Choose an appropriate task prefix/trigger word and jus'fy the choice.\n",
    "#### 12. Evaluate the quality of the model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc2c7fdb",
   "metadata": {},
   "source": [
    "##### 10. Reload the original google/flan-t5-small model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "b885d3e5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:__main__:Loading model: google/flan-t5-small\n",
      "INFO:__main__:Model loaded successfully\n"
     ]
    }
   ],
   "source": [
    "tokenizer, model = load_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "953fbd64",
   "metadata": {},
   "outputs": [],
   "source": [
    "#model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "50b217b8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "T5Config {\n",
       "  \"_name_or_path\": \"google/flan-t5-small\",\n",
       "  \"architectures\": [\n",
       "    \"T5ForConditionalGeneration\"\n",
       "  ],\n",
       "  \"classifier_dropout\": 0.0,\n",
       "  \"d_ff\": 1024,\n",
       "  \"d_kv\": 64,\n",
       "  \"d_model\": 512,\n",
       "  \"decoder_start_token_id\": 0,\n",
       "  \"dense_act_fn\": \"gelu_new\",\n",
       "  \"dropout_rate\": 0.1,\n",
       "  \"eos_token_id\": 1,\n",
       "  \"feed_forward_proj\": \"gated-gelu\",\n",
       "  \"initializer_factor\": 1.0,\n",
       "  \"is_encoder_decoder\": true,\n",
       "  \"is_gated_act\": true,\n",
       "  \"layer_norm_epsilon\": 1e-06,\n",
       "  \"model_type\": \"t5\",\n",
       "  \"n_positions\": 512,\n",
       "  \"num_decoder_layers\": 8,\n",
       "  \"num_heads\": 6,\n",
       "  \"num_layers\": 8,\n",
       "  \"output_past\": true,\n",
       "  \"pad_token_id\": 0,\n",
       "  \"relative_attention_max_distance\": 128,\n",
       "  \"relative_attention_num_buckets\": 32,\n",
       "  \"task_specific_params\": {\n",
       "    \"summarization\": {\n",
       "      \"early_stopping\": true,\n",
       "      \"length_penalty\": 2.0,\n",
       "      \"max_length\": 200,\n",
       "      \"min_length\": 30,\n",
       "      \"no_repeat_ngram_size\": 3,\n",
       "      \"num_beams\": 4,\n",
       "      \"prefix\": \"summarize: \"\n",
       "    },\n",
       "    \"translation_en_to_de\": {\n",
       "      \"early_stopping\": true,\n",
       "      \"max_length\": 300,\n",
       "      \"num_beams\": 4,\n",
       "      \"prefix\": \"translate English to German: \"\n",
       "    },\n",
       "    \"translation_en_to_fr\": {\n",
       "      \"early_stopping\": true,\n",
       "      \"max_length\": 300,\n",
       "      \"num_beams\": 4,\n",
       "      \"prefix\": \"translate English to French: \"\n",
       "    },\n",
       "    \"translation_en_to_ro\": {\n",
       "      \"early_stopping\": true,\n",
       "      \"max_length\": 300,\n",
       "      \"num_beams\": 4,\n",
       "      \"prefix\": \"translate English to Romanian: \"\n",
       "    }\n",
       "  },\n",
       "  \"tie_word_embeddings\": false,\n",
       "  \"transformers_version\": \"4.36.2\",\n",
       "  \"use_cache\": true,\n",
       "  \"vocab_size\": 32128\n",
       "}"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.config"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3cfd494d",
   "metadata": {},
   "source": [
    "### Fine tuning step "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1322cfd4",
   "metadata": {},
   "source": [
    "#### 1. Dataset Download\n",
    "#### 2.Data Preparation\n",
    "#### 3.Model:Choose the FLAN T5 :Load the Pre-trained Model:\n",
    "#### 4.Fine-Tuning\n",
    "#### 5.Evaluation\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f75938be",
   "metadata": {},
   "source": [
    "#### Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35b54e67",
   "metadata": {},
   "source": [
    "https://mcgill-nlp.github.io/topiocqa/"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24eb8187",
   "metadata": {},
   "source": [
    "#### About Topioca Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0a9a989",
   "metadata": {},
   "source": [
    "Format: Each entry in the dataset consists of a question and its corresponding answer. The dataset may also include a context paragraph providing background or related information for the question, but the answer does not have to be a direct excerpt from this context.\n",
    "Diversity: The dataset includes a variety of question types and subjects, making it a comprehensive resource for training generalized QA model.\n",
    "\n",
    "Example\n",
    "\n",
    "Context: \"The Eiffel Tower is a wrought-iron lattice tower on the Champ de Mars in Paris, France.\"\n",
    "\n",
    "Question: \"Where is the Eiffel Tower located?\"\n",
    "\n",
    "Answer: \"Paris, France\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "55ccf237",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "from torch.utils.data import Dataset, DataLoader, RandomSampler\n",
    "# Configure basic logging\n",
    "logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "dd6ae95c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_json_file_formatting(path, file_name):\n",
    "    \"\"\"\n",
    "    Loads a JSON file from the given path and file name.\n",
    "\n",
    "    Args:\n",
    "    path (str): The path to the directory containing the JSON file.\n",
    "    file_name (str): The name of the JSON file.\n",
    "\n",
    "    Returns:\n",
    "    dict: The content of the JSON file, or None if an error occurs.\n",
    "    \"\"\"\n",
    "    full_path = os.path.join(path, file_name)\n",
    "\n",
    "    try:\n",
    "        with open(full_path, 'r') as f:\n",
    "            data = json.load(f)\n",
    "            logging.info(f\"Successfully loaded file: {full_path}\")\n",
    "            return data\n",
    "    except FileNotFoundError:\n",
    "        logging.error(f\"File not found: {full_path}\")\n",
    "    except json.JSONDecodeError as e:\n",
    "        logging.error(f\"Error decoding JSON from file {file_name}: {e}\")\n",
    "    except Exception as e:\n",
    "        logging.error(f\"An unexpected error occurred while reading {file_name}: {e}\")\n",
    "\n",
    "    return None"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57071f79",
   "metadata": {},
   "source": [
    "#### reading the training file  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "fe75a92d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the current working directory\n",
    "current_working_directory = os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "2b17e594",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example usage\n",
    "folder_path = current_working_directory\n",
    "qa_train = 'topiocqa_train.json'\n",
    "qa_dev=\"topiocqa_dev.json\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "18b6b660",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Successfully loaded file: C:\\Users\\verma\\OneDrive\\Desktop\\LLM_TUTORIAL\\topiocqa_train.json\n"
     ]
    }
   ],
   "source": [
    "data_train = load_json_file_formatting(folder_path, qa_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "4729e169",
   "metadata": {},
   "outputs": [],
   "source": [
    "#data_train[\"data\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "e5a409fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Successfully loaded file: C:\\Users\\verma\\OneDrive\\Desktop\\LLM_TUTORIAL\\topiocqa_dev.json\n"
     ]
    }
   ],
   "source": [
    "data_dev = load_json_file_formatting(folder_path, qa_dev)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "257c5cbb",
   "metadata": {},
   "source": [
    "#### Data Preprocessing and formating"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "7ca5ba99",
   "metadata": {},
   "outputs": [],
   "source": [
    "def json_to_dataframe(json_file_path):\n",
    "    # Read the JSON file\n",
    "    with open(json_file_path, 'r') as file:\n",
    "        data = json.load(file)\n",
    "    \n",
    "    # Extracting the relevant fields\n",
    "    df_data = []\n",
    "    for item in data:\n",
    "        context = item.get('Context', '')\n",
    "        question = item.get('Question', '')\n",
    "        answer = item.get('Answer', '')\n",
    "\n",
    "        # Add to the list as a tuple\n",
    "        df_data.append((context, question, answer))\n",
    "\n",
    "    # Create a DataFrame\n",
    "    df = pd.DataFrame(df_data, columns=['Context', 'Question', 'Answer'])\n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "44ac439e",
   "metadata": {},
   "outputs": [],
   "source": [
    "topioca_data_frame= json_to_dataframe(qa_train)\n",
    "topioca_data_frame_dev= json_to_dataframe(qa_dev)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2328df09",
   "metadata": {},
   "source": [
    "### saving data in csv file format "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "ff5d0439",
   "metadata": {},
   "outputs": [],
   "source": [
    "#topioca_data_frame.to_csv(\"Topioca_data.csv\",index=False)\n",
    "#topioca_data_frame_dev.to_csv(\"Topioca_data_dev.csv\",index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "a3c1b19e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#reading the csv file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "e6d70f84",
   "metadata": {},
   "outputs": [],
   "source": [
    "topica_csv=pd.read_csv(\"Topioca_data.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "595f53c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "dev_topica_csv=pd.read_csv(\"Topioca_data_dev.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "4b1426c1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Context</th>\n",
       "      <th>Question</th>\n",
       "      <th>Answer</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[]</td>\n",
       "      <td>what was australia's contribution to the battl...</td>\n",
       "      <td>The army personnel and thousands of Australian...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[\"what was australia's contribution to the bat...</td>\n",
       "      <td>was the battle fought in australia?</td>\n",
       "      <td>UNANSWERABLE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[\"what was australia's contribution to the bat...</td>\n",
       "      <td>when was the battle fought?</td>\n",
       "      <td>1944</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[\"what was australia's contribution to the bat...</td>\n",
       "      <td>who fought in this battle?</td>\n",
       "      <td>Australians and British</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[\"what was australia's contribution to the bat...</td>\n",
       "      <td>was this battle part of a bigger war?</td>\n",
       "      <td>UNANSWERABLE</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             Context  \\\n",
       "0                                                 []   \n",
       "1  [\"what was australia's contribution to the bat...   \n",
       "2  [\"what was australia's contribution to the bat...   \n",
       "3  [\"what was australia's contribution to the bat...   \n",
       "4  [\"what was australia's contribution to the bat...   \n",
       "\n",
       "                                            Question  \\\n",
       "0  what was australia's contribution to the battl...   \n",
       "1                was the battle fought in australia?   \n",
       "2                        when was the battle fought?   \n",
       "3                         who fought in this battle?   \n",
       "4              was this battle part of a bigger war?   \n",
       "\n",
       "                                              Answer  \n",
       "0  The army personnel and thousands of Australian...  \n",
       "1                                       UNANSWERABLE  \n",
       "2                                               1944  \n",
       "3                            Australians and British  \n",
       "4                                       UNANSWERABLE  "
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "topica_csv.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "2cdbd8d9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Context</th>\n",
       "      <th>Question</th>\n",
       "      <th>Answer</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[]</td>\n",
       "      <td>when will the new dunkirk film be released on dvd</td>\n",
       "      <td>18 December 2017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>['when will the new dunkirk film be released o...</td>\n",
       "      <td>what is this film about?</td>\n",
       "      <td>Dunkirk evacuation of World War II</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>['when will the new dunkirk film be released o...</td>\n",
       "      <td>can you mention a few members of the cast?</td>\n",
       "      <td>Fionn Whitehead, Tom Glynn-Carney, Jack Lowden...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>['when will the new dunkirk film be released o...</td>\n",
       "      <td>where was it shot?</td>\n",
       "      <td>Dunkirk and Urk, Netherlands</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>['when will the new dunkirk film be released o...</td>\n",
       "      <td>can you tell me anything about the latter plac...</td>\n",
       "      <td>Until 1475 the High and Low Lordship of Urk an...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             Context  \\\n",
       "0                                                 []   \n",
       "1  ['when will the new dunkirk film be released o...   \n",
       "2  ['when will the new dunkirk film be released o...   \n",
       "3  ['when will the new dunkirk film be released o...   \n",
       "4  ['when will the new dunkirk film be released o...   \n",
       "\n",
       "                                            Question  \\\n",
       "0  when will the new dunkirk film be released on dvd   \n",
       "1                           what is this film about?   \n",
       "2         can you mention a few members of the cast?   \n",
       "3                                 where was it shot?   \n",
       "4  can you tell me anything about the latter plac...   \n",
       "\n",
       "                                              Answer  \n",
       "0                                   18 December 2017  \n",
       "1                 Dunkirk evacuation of World War II  \n",
       "2  Fionn Whitehead, Tom Glynn-Carney, Jack Lowden...  \n",
       "3                       Dunkirk and Urk, Netherlands  \n",
       "4  Until 1475 the High and Low Lordship of Urk an...  "
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dev_topica_csv.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "0ff1f512",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Context     0\n",
       "Question    0\n",
       "Answer      0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "topica_csv.isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7647ef3d",
   "metadata": {},
   "source": [
    "#### For training, a smaller subset of data is being selected due to limitations in CPU and GPU resources."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "1835517b",
   "metadata": {},
   "outputs": [],
   "source": [
    "topica_csv_sample=topica_csv.iloc[0:4000,:]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a46ed490",
   "metadata": {},
   "source": [
    "### Data Prepration Train Val set "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "930b4df9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_dataset(csv_data):\n",
    "    \"\"\"\n",
    "    Prepares the dataset by creating input and target text columns, and splitting the data into training and validation sets.\n",
    "\n",
    "    Parameters:\n",
    "    csv_data (DataFrame): A pandas DataFrame containing the dataset with 'Context', 'Question', and 'Answer' columns.\n",
    "\n",
    "    Returns:\n",
    "    tuple: A tuple containing two DataFrames (train_df, val_df) for training and validation sets.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Add input_text and target_text columns\n",
    "        csv_data['input_text'] = 'context: ' + csv_data['Context'] + ' question: ' + csv_data['Question']\n",
    "        csv_data['target_text'] = csv_data['Answer']\n",
    "\n",
    "        # Split the dataset into training and validation sets\n",
    "        train_df = csv_data.sample(frac=0.8, random_state=200)\n",
    "        val_df = csv_data.drop(train_df.index)\n",
    "\n",
    "        logging.info(\"Dataset preparation complete.\")\n",
    "        return train_df, val_df\n",
    "\n",
    "    except Exception as e:\n",
    "        logging.error(f\"Error occurred during dataset preparation: {e}\")\n",
    "        raise\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "9686f51d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:datasets:PyTorch version 2.1.2 available.\n"
     ]
    }
   ],
   "source": [
    "from transformers import T5Tokenizer, T5ForConditionalGeneration, Trainer, TrainingArguments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "8c9ecd2e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You are using the default legacy behaviour of the <class 'transformers.models.t5.tokenization_t5.T5Tokenizer'>. This is expected, and simply means that the `legacy` (previous) behavior will be used so nothing changes for you. If you want to use the new behaviour, set `legacy=False`. This should only be set if you understand what it means, and thouroughly read the reason why this was added as explained in https://github.com/huggingface/transformers/pull/24565\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
     ]
    }
   ],
   "source": [
    "# Initialize the tokenizer\n",
    "tokenizer = T5Tokenizer.from_pretrained('google/flan-t5-small')"
   ]
  },
  {
   "cell_type": "raw",
   "id": "1077c827",
   "metadata": {},
   "source": [
    "topica_csv['input_text'] = 'context: ' + topica_csv['Context'] + ' question: ' + topica_csv['Question']\n",
    "topica_csv['target_text'] = topica_csv['Answer']\n"
   ]
  },
  {
   "cell_type": "raw",
   "id": "1ea9ad9b",
   "metadata": {},
   "source": [
    "# Split the dataset\n",
    "train_df = topica_csv.sample(frac=0.8, random_state=200)\n",
    "val_df = topica_csv.drop(train_df.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "94d75455",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Dataset preparation complete.\n"
     ]
    }
   ],
   "source": [
    "train_df,val_df=prepare_dataset(topica_csv_sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "bec9dfc5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
     ]
    }
   ],
   "source": [
    "tokenizer = T5Tokenizer.from_pretrained('google/flan-t5-small')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "874ddd00",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Context</th>\n",
       "      <th>Question</th>\n",
       "      <th>Answer</th>\n",
       "      <th>input_text</th>\n",
       "      <th>target_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>501</th>\n",
       "      <td>['what is durian?', 'It is the fruit of severa...</td>\n",
       "      <td>what kind of places does the first one live in?</td>\n",
       "      <td>Lowland and hill forests</td>\n",
       "      <td>context: ['what is durian?', 'It is the fruit ...</td>\n",
       "      <td>Lowland and hill forests</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3118</th>\n",
       "      <td>['where did the field of fire take place', 'UN...</td>\n",
       "      <td>has he been referred to in popular culture or ...</td>\n",
       "      <td>John Betjeman's poem \"A Shropshire Lad\" (1940)...</td>\n",
       "      <td>context: ['where did the field of fire take pl...</td>\n",
       "      <td>John Betjeman's poem \"A Shropshire Lad\" (1940)...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>228</th>\n",
       "      <td>[\"who's directing the new blade runner movie\",...</td>\n",
       "      <td>are there concerns over the environment?</td>\n",
       "      <td>A federal environmental programme was establis...</td>\n",
       "      <td>context: [\"who's directing the new blade runne...</td>\n",
       "      <td>A federal environmental programme was establis...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2879</th>\n",
       "      <td>[]</td>\n",
       "      <td>who is calvin coolidge?</td>\n",
       "      <td>American politician and lawyer who served as t...</td>\n",
       "      <td>context: [] question: who is calvin coolidge?</td>\n",
       "      <td>American politician and lawyer who served as t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1220</th>\n",
       "      <td>['when does the punisher make an appearance in...</td>\n",
       "      <td>who is the writer?</td>\n",
       "      <td>UNANSWERABLE</td>\n",
       "      <td>context: ['when does the punisher make an appe...</td>\n",
       "      <td>UNANSWERABLE</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                Context  \\\n",
       "501   ['what is durian?', 'It is the fruit of severa...   \n",
       "3118  ['where did the field of fire take place', 'UN...   \n",
       "228   [\"who's directing the new blade runner movie\",...   \n",
       "2879                                                 []   \n",
       "1220  ['when does the punisher make an appearance in...   \n",
       "\n",
       "                                               Question  \\\n",
       "501     what kind of places does the first one live in?   \n",
       "3118  has he been referred to in popular culture or ...   \n",
       "228            are there concerns over the environment?   \n",
       "2879                            who is calvin coolidge?   \n",
       "1220                                 who is the writer?   \n",
       "\n",
       "                                                 Answer  \\\n",
       "501                            Lowland and hill forests   \n",
       "3118  John Betjeman's poem \"A Shropshire Lad\" (1940)...   \n",
       "228   A federal environmental programme was establis...   \n",
       "2879  American politician and lawyer who served as t...   \n",
       "1220                                       UNANSWERABLE   \n",
       "\n",
       "                                             input_text  \\\n",
       "501   context: ['what is durian?', 'It is the fruit ...   \n",
       "3118  context: ['where did the field of fire take pl...   \n",
       "228   context: [\"who's directing the new blade runne...   \n",
       "2879      context: [] question: who is calvin coolidge?   \n",
       "1220  context: ['when does the punisher make an appe...   \n",
       "\n",
       "                                            target_text  \n",
       "501                            Lowland and hill forests  \n",
       "3118  John Betjeman's poem \"A Shropshire Lad\" (1940)...  \n",
       "228   A federal environmental programme was establis...  \n",
       "2879  American politician and lawyer who served as t...  \n",
       "1220                                       UNANSWERABLE  "
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "8324a1ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Custom Dataset class\n",
    "class QADataset(Dataset):\n",
    "    def __init__(self, tokenizer, data):\n",
    "        self.tokenizer = tokenizer\n",
    "        self.data = data\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        row = self.data.iloc[idx]\n",
    "        inputs = self.tokenizer.encode_plus(\n",
    "            row['input_text'], \n",
    "            None, \n",
    "            add_special_tokens=True,\n",
    "            max_length=512,\n",
    "            padding='max_length',\n",
    "            return_token_type_ids=False,\n",
    "            return_attention_mask=True,\n",
    "            truncation=True\n",
    "        )\n",
    "        outputs = self.tokenizer.encode(\n",
    "            row['target_text'],\n",
    "            add_special_tokens=True,\n",
    "            max_length=512,\n",
    "            padding='max_length',\n",
    "            truncation=True\n",
    "        )\n",
    "\n",
    "        return {\n",
    "            'input_ids': torch.tensor(inputs['input_ids'], dtype=torch.long),\n",
    "            'attention_mask': torch.tensor(inputs['attention_mask'], dtype=torch.long),\n",
    "            'labels': torch.tensor(outputs, dtype=torch.long)\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "33459c2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare datasets\n",
    "train_dataset = QADataset(tokenizer, train_df)\n",
    "val_dataset = QADataset(tokenizer, val_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "09e94844",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Context</th>\n",
       "      <th>Question</th>\n",
       "      <th>Answer</th>\n",
       "      <th>input_text</th>\n",
       "      <th>target_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>501</th>\n",
       "      <td>['what is durian?', 'It is the fruit of severa...</td>\n",
       "      <td>what kind of places does the first one live in?</td>\n",
       "      <td>Lowland and hill forests</td>\n",
       "      <td>context: ['what is durian?', 'It is the fruit ...</td>\n",
       "      <td>Lowland and hill forests</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3118</th>\n",
       "      <td>['where did the field of fire take place', 'UN...</td>\n",
       "      <td>has he been referred to in popular culture or ...</td>\n",
       "      <td>John Betjeman's poem \"A Shropshire Lad\" (1940)...</td>\n",
       "      <td>context: ['where did the field of fire take pl...</td>\n",
       "      <td>John Betjeman's poem \"A Shropshire Lad\" (1940)...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>228</th>\n",
       "      <td>[\"who's directing the new blade runner movie\",...</td>\n",
       "      <td>are there concerns over the environment?</td>\n",
       "      <td>A federal environmental programme was establis...</td>\n",
       "      <td>context: [\"who's directing the new blade runne...</td>\n",
       "      <td>A federal environmental programme was establis...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2879</th>\n",
       "      <td>[]</td>\n",
       "      <td>who is calvin coolidge?</td>\n",
       "      <td>American politician and lawyer who served as t...</td>\n",
       "      <td>context: [] question: who is calvin coolidge?</td>\n",
       "      <td>American politician and lawyer who served as t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1220</th>\n",
       "      <td>['when does the punisher make an appearance in...</td>\n",
       "      <td>who is the writer?</td>\n",
       "      <td>UNANSWERABLE</td>\n",
       "      <td>context: ['when does the punisher make an appe...</td>\n",
       "      <td>UNANSWERABLE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3877</th>\n",
       "      <td>['is the simpsons a type of animation?', 'Yes,...</td>\n",
       "      <td>what else did the first voice artist do after ...</td>\n",
       "      <td>He made guest appearances in TV shows, includi...</td>\n",
       "      <td>context: ['is the simpsons a type of animation...</td>\n",
       "      <td>He made guest appearances in TV shows, includi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2169</th>\n",
       "      <td>[]</td>\n",
       "      <td>when did immigrants stop coming to ellis island</td>\n",
       "      <td>1924</td>\n",
       "      <td>context: [] question: when did immigrants stop...</td>\n",
       "      <td>1924</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2196</th>\n",
       "      <td>[\"what is 'the wrong goodbye (gossip girl)'?\",...</td>\n",
       "      <td>is there any controversy related to that chara...</td>\n",
       "      <td>Yes, Chuck's public humiliation of Blair, his ...</td>\n",
       "      <td>context: [\"what is 'the wrong goodbye (gossip ...</td>\n",
       "      <td>Yes, Chuck's public humiliation of Blair, his ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2537</th>\n",
       "      <td>[]</td>\n",
       "      <td>when do they leave the farm walking dead</td>\n",
       "      <td>in the 13th and final episode of the second se...</td>\n",
       "      <td>context: [] question: when do they leave the f...</td>\n",
       "      <td>in the 13th and final episode of the second se...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3818</th>\n",
       "      <td>['how much does the mayor of atlanta make', 'U...</td>\n",
       "      <td>what sports are they involved in?</td>\n",
       "      <td>Baseball, basketball, lacrosse</td>\n",
       "      <td>context: ['how much does the mayor of atlanta ...</td>\n",
       "      <td>Baseball, basketball, lacrosse</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3200 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                Context  \\\n",
       "501   ['what is durian?', 'It is the fruit of severa...   \n",
       "3118  ['where did the field of fire take place', 'UN...   \n",
       "228   [\"who's directing the new blade runner movie\",...   \n",
       "2879                                                 []   \n",
       "1220  ['when does the punisher make an appearance in...   \n",
       "...                                                 ...   \n",
       "3877  ['is the simpsons a type of animation?', 'Yes,...   \n",
       "2169                                                 []   \n",
       "2196  [\"what is 'the wrong goodbye (gossip girl)'?\",...   \n",
       "2537                                                 []   \n",
       "3818  ['how much does the mayor of atlanta make', 'U...   \n",
       "\n",
       "                                               Question  \\\n",
       "501     what kind of places does the first one live in?   \n",
       "3118  has he been referred to in popular culture or ...   \n",
       "228            are there concerns over the environment?   \n",
       "2879                            who is calvin coolidge?   \n",
       "1220                                 who is the writer?   \n",
       "...                                                 ...   \n",
       "3877  what else did the first voice artist do after ...   \n",
       "2169    when did immigrants stop coming to ellis island   \n",
       "2196  is there any controversy related to that chara...   \n",
       "2537           when do they leave the farm walking dead   \n",
       "3818                  what sports are they involved in?   \n",
       "\n",
       "                                                 Answer  \\\n",
       "501                            Lowland and hill forests   \n",
       "3118  John Betjeman's poem \"A Shropshire Lad\" (1940)...   \n",
       "228   A federal environmental programme was establis...   \n",
       "2879  American politician and lawyer who served as t...   \n",
       "1220                                       UNANSWERABLE   \n",
       "...                                                 ...   \n",
       "3877  He made guest appearances in TV shows, includi...   \n",
       "2169                                               1924   \n",
       "2196  Yes, Chuck's public humiliation of Blair, his ...   \n",
       "2537  in the 13th and final episode of the second se...   \n",
       "3818                     Baseball, basketball, lacrosse   \n",
       "\n",
       "                                             input_text  \\\n",
       "501   context: ['what is durian?', 'It is the fruit ...   \n",
       "3118  context: ['where did the field of fire take pl...   \n",
       "228   context: [\"who's directing the new blade runne...   \n",
       "2879      context: [] question: who is calvin coolidge?   \n",
       "1220  context: ['when does the punisher make an appe...   \n",
       "...                                                 ...   \n",
       "3877  context: ['is the simpsons a type of animation...   \n",
       "2169  context: [] question: when did immigrants stop...   \n",
       "2196  context: [\"what is 'the wrong goodbye (gossip ...   \n",
       "2537  context: [] question: when do they leave the f...   \n",
       "3818  context: ['how much does the mayor of atlanta ...   \n",
       "\n",
       "                                            target_text  \n",
       "501                            Lowland and hill forests  \n",
       "3118  John Betjeman's poem \"A Shropshire Lad\" (1940)...  \n",
       "228   A federal environmental programme was establis...  \n",
       "2879  American politician and lawyer who served as t...  \n",
       "1220                                       UNANSWERABLE  \n",
       "...                                                 ...  \n",
       "3877  He made guest appearances in TV shows, includi...  \n",
       "2169                                               1924  \n",
       "2196  Yes, Chuck's public humiliation of Blair, his ...  \n",
       "2537  in the 13th and final episode of the second se...  \n",
       "3818                     Baseball, basketball, lacrosse  \n",
       "\n",
       "[3200 rows x 5 columns]"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dataset.data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "89701bf9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model\n",
    "model = T5ForConditionalGeneration.from_pretrained('google/flan-t5-small')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "1a4f657e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training arguments\n",
    "training_args = TrainingArguments(\n",
    "    output_dir='./results',\n",
    "    num_train_epochs=1,\n",
    "    per_device_train_batch_size=16,\n",
    "    per_device_eval_batch_size=16,\n",
    "    warmup_steps=50,\n",
    "    weight_decay=0.01,\n",
    "    logging_dir='./logs',\n",
    "    logging_steps=10,\n",
    ")\n",
    "\n",
    "# Initialize the Trainer\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=train_dataset,\n",
    "    eval_dataset=val_dataset\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "1ce6302d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='200' max='200' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [200/200 4:24:27, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>43.506900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20</td>\n",
       "      <td>41.573700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>30</td>\n",
       "      <td>38.789200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>40</td>\n",
       "      <td>34.832600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>50</td>\n",
       "      <td>30.537500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>60</td>\n",
       "      <td>24.997300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>70</td>\n",
       "      <td>18.137300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>80</td>\n",
       "      <td>11.313000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>90</td>\n",
       "      <td>7.445400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>5.763700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>110</td>\n",
       "      <td>4.917900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>120</td>\n",
       "      <td>4.507900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>130</td>\n",
       "      <td>4.354000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>140</td>\n",
       "      <td>4.194800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>150</td>\n",
       "      <td>4.104900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>160</td>\n",
       "      <td>3.908100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>170</td>\n",
       "      <td>3.918900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>180</td>\n",
       "      <td>3.842900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>190</td>\n",
       "      <td>3.743100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>3.749900</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=200, training_loss=14.906954383850097, metrics={'train_runtime': 15924.7566, 'train_samples_per_second': 0.201, 'train_steps_per_second': 0.013, 'total_flos': 594849615052800.0, 'train_loss': 14.906954383850097, 'epoch': 1.0})"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Train the model\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "9401e13f",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save_pretrained('./flan-T5-QA-Finetune')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02a2db51",
   "metadata": {},
   "source": [
    "### Evaluating a trained model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b81b8501",
   "metadata": {},
   "source": [
    "Evaluating a trained model for a task like question-answering can be done using various metrics such as ROUGE, BLEU, and perplexity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "73a38f67",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "import rouge_score\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "cb66c0e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install sacrebleu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "d4ec7176",
   "metadata": {},
   "outputs": [],
   "source": [
    "#nltk.download('all')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "42dfd3e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Token indices sequence length is longer than the specified maximum sequence length for this model (608 > 512). Running this sequence through the model will result in indexing errors\n",
      "INFO:absl:Using default tokenizer.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ROUGE Score: {'rouge1': AggregateScore(low=Score(precision=0.0, recall=0.0, fmeasure=0.0), mid=Score(precision=0.00375, recall=0.0006547619047619048, fmeasure=0.0008914728682170542), high=Score(precision=0.00875, recall=0.0021138392857142853, fmeasure=0.0029543298653610752)), 'rouge2': AggregateScore(low=Score(precision=0.0, recall=0.0, fmeasure=0.0), mid=Score(precision=0.0, recall=0.0, fmeasure=0.0), high=Score(precision=0.0, recall=0.0, fmeasure=0.0)), 'rougeL': AggregateScore(low=Score(precision=0.0, recall=0.0, fmeasure=0.0), mid=Score(precision=0.00375, recall=0.0006944444444444445, fmeasure=0.0009649122807017543), high=Score(precision=0.007531249999999971, recall=0.0021436011904761897, fmeasure=0.0030124694002447963)), 'rougeLsum': AggregateScore(low=Score(precision=0.0, recall=0.0, fmeasure=0.0), mid=Score(precision=0.00375, recall=0.0006845238095238096, fmeasure=0.000949612403100775), high=Score(precision=0.00875, recall=0.002113095238095238, fmeasure=0.0029528763769889835))}\n",
      "BLEU Score: {'score': 0.0063597902643091255, 'counts': [3227, 1600, 0, 0], 'totals': [3329, 2529, 1729, 929], 'precisions': [96.93601682186844, 63.26611308817714, 0.02891844997108155, 0.02691065662002153], 'bp': 0.004302827010783156, 'sys_len': 3329, 'ref_len': 21467}\n",
      "Perplexity: 2.5805561542510986\n"
     ]
    }
   ],
   "source": [
    "from datasets import load_metric\n",
    "# Load the trained model and tokenizer\n",
    "model = T5ForConditionalGeneration.from_pretrained('./flan-T5-QA-Finetune')\n",
    "tokenizer = T5Tokenizer.from_pretrained('google/flan-t5-small')\n",
    "\n",
    "# Load your validation dataset\n",
    "val_df = val_df\n",
    "\n",
    "# Metrics\n",
    "rouge = load_metric('rouge')\n",
    "bleu = load_metric('sacrebleu')\n",
    "\n",
    "# Function to generate answers from the model\n",
    "def generate_answer(input_text):\n",
    "    input_ids = tokenizer(input_text, return_tensors=\"pt\").input_ids\n",
    "    output_ids = model.generate(input_ids)[0]\n",
    "    return tokenizer.decode(output_ids, skip_special_tokens=True)\n",
    "\n",
    "# Evaluate ROUGE and BLEU\n",
    "for index, row in val_df.iterrows():\n",
    "    context = row['Context']\n",
    "    question = row['Question']\n",
    "    answer = row['Answer']\n",
    "    input_text = f\"context: {context} question: {question}\"\n",
    "    \n",
    "    predicted_answer = generate_answer(input_text)\n",
    "    rouge.add(prediction=predicted_answer, reference=answer)\n",
    "    bleu.add(prediction=[predicted_answer.split()], reference=[[answer.split()]])\n",
    "\n",
    "# Calculate final scores\n",
    "rouge_score = rouge.compute()\n",
    "bleu_score = bleu.compute()\n",
    "\n",
    "print(\"ROUGE Score:\", rouge_score)\n",
    "print(\"BLEU Score:\", bleu_score)\n",
    "\n",
    "# Evaluate Perplexity\n",
    "def calculate_perplexity(text):\n",
    "    inputs = tokenizer(text, return_tensors=\"pt\")\n",
    "    outputs = model(**inputs, labels=inputs[\"input_ids\"])\n",
    "    return torch.exp(outputs[0])\n",
    "\n",
    "# Example: Calculate perplexity for a sample text\n",
    "sample_text = \"Your sample text here.\"\n",
    "perplexity = calculate_perplexity(sample_text)\n",
    "print(\"Perplexity:\", perplexity.item())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "900cbc6d",
   "metadata": {},
   "source": [
    "### Next Step For Fine Tuning : Retrieval-Augmented Generation (RAG) model  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc8e7b0a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
